{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bef2c03-3478-4655-9434-c3ac61e95fae",
   "metadata": {},
   "source": [
    "<h1> 501 Data Pipeline Workshop 9/24 </h1>\n",
    "<h3> Part 2: Network Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a2a16-dd72-4689-9420-84b641d312b6",
   "metadata": {},
   "source": [
    "<p>Now that we're more familiar with the data and have some ideas, let's build an agent based model to simulate the flow of information across the \"thought collective\"</p>\n",
    "<p>In the model, each creator is a node, and when two or more creators are listed for a single document, that usually means they are corresponding via letter, or collaborating on a project. Letters and collaborations are communicative pathways over which new ideas can be transmitted.</p>\n",
    "<p>How far and at what speed might a new idea traverse this network, if it originated with one of our hub scientists?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0946f9-5252-4304-8e00-74e2fbaf18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "# Some the same as part 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Networkx for building a network to visualize\n",
    "import networkx as nx\n",
    "# Itertools for making combinations\n",
    "import itertools\n",
    "# Random for instantiating random variables when we run the simulation\n",
    "import random\n",
    "\n",
    "# These are for running the simulation in a readable way\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "## And we need to import the cybernetics data again from the csv file\n",
    "cybernetics_data = pd.read_csv ('CTC_Machine-Generated-Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7871c0-55e3-4f54-bcdd-153ced2b9f82",
   "metadata": {},
   "source": [
    "<h3>To build a network in networkx, we are going to make a list of nodes and a dataframe with information about edges.</h3>\n",
    "<p>The nodes will be pairs of document creators, a proxy for people in communication with one another. The edges dataframe will record source, target, and weight for each edge. Weight here is the frequency of occurence, or how many times these two people are listed together in a document.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1496428-1e34-410c-be97-80692417d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up a network\n",
    "\n",
    "# List all the creators\n",
    "creator_list = []\n",
    "for i in cybernetics_data['Creator']:\n",
    "    if not pd.isna(i):\n",
    "        creator_list.append(i.split('||'))\n",
    "\n",
    "# Remove duplicates\n",
    "creator_set = [item for sublist in creator_list for item in sublist]\n",
    "creator_set = set(creator_set)\n",
    "\n",
    "# Create an empty edges dataframe with 'Source', 'Target', and 'Weight' columns\n",
    "column_names = ['Source', 'Target', 'Weight']\n",
    "edges_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Turn every creator list into pairs\n",
    "new_creator_list=[]\n",
    "for entry in creator_list:\n",
    "    if len(entry)==2:\n",
    "        new_creator_list.append(entry)\n",
    "    elif len(entry)>2:\n",
    "        for combination in itertools.combinations(entry, 2):\n",
    "            new_creator_list.append(list(combination))\n",
    "\n",
    "data_series = pd.Series(new_creator_list)\n",
    "\n",
    "# Calculate the frequency of each unique value\n",
    "frequency_table = data_series.value_counts().reset_index()\n",
    "\n",
    "# Fill in the edges dataframe from the frequency table\n",
    "for row in range(len(frequency_table)):\n",
    "    edges_df.at[row, 'Source'] = frequency_table['index'][row][0]\n",
    "    edges_df.at[row, 'Target'] = frequency_table['index'][row][1]\n",
    "    edges_df.at[row, 'Weight'] = frequency_table['count'][row]\n",
    "\n",
    "display (edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4160b9-3718-4b81-96cd-fdb5642ebdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can make and print a representation of the network\n",
    "\n",
    "# Make an undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "G.add_nodes_from(list(creator_set))\n",
    "\n",
    "# Add edges\n",
    "G = nx.from_pandas_edgelist(edges_df, source='Source', target='Target', edge_attr='Weight')\n",
    "\n",
    "# Set up a layout (this moves around the node positions to a legible layout)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "# Set figure size\n",
    "plt.rcParams[\"figure.figsize\"] = [30, 30]\n",
    "\n",
    "# Define the nodes you want to label\n",
    "hubs= ['Wiener, Norbert', 'McCulloch, Warren S.','von Foerster, Heinz']\n",
    "\n",
    "labels = {}    \n",
    "for node in G.nodes():\n",
    "    if node in hubs:\n",
    "        #set the node name as the key and the label as its value \n",
    "        labels[node] = node\n",
    "\n",
    "# Draw the network\n",
    "nx.draw(G, pos, width=edges_df['Weight'], with_labels=False, node_color='skyblue', edge_color='gray', node_size=90)\n",
    "\n",
    "# Draw the labels for the hub nodes\n",
    "nx.draw_networkx_labels(G, pos, labels=labels, font_size=36, font_color='black')\n",
    "\n",
    "# repositioning the nodes takes a bit so give this code a minute to run\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f02f9-178c-4834-9213-618c0bebc50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you use gephi, you can use this cell to save the network so that you can open it in gephi and play around with some different layouts\n",
    "nx.write_gexf(G, \"cyber_network.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b296b3-95e5-4798-8ed7-78d75839875a",
   "metadata": {},
   "source": [
    "<h3>We want to see how information flows over this network over time.</h3>\n",
    "<p>We can do that without actually using the networkx constructed network, but instead testing for individual links over time.\n",
    "<br>We can also include some additional information for each edge, related to the machine extracted topics of discussion in each document.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4d115-fec1-46c9-8bd5-0564e91d7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a new network dataframe to use in the simulation\n",
    "\n",
    "# First we need to add a year column to clean up the 'Date' column and make it a single year for that document/communication\n",
    "# This is a HUGE simplification of the archival data, but the most straightforward way to deal with 'years' for our toy model.\n",
    "cybernetics_data['year'] = cybernetics_data['Date'].str.split('-|\\|\\|').str.get(0)\n",
    "cybernetics_data['year'] = cybernetics_data['year'].str.replace(r'[^0-9]', '', regex=True)\n",
    "cybernetics_data['year'] = pd.to_numeric(cybernetics_data['year'])\n",
    "\n",
    "# Next, we break up the 'Classification Certainty (Machine Generated)' into its component percentages\n",
    "cybernetics_data['personal'] = cybernetics_data['Classification Certainty (Machine Generated)'].str.extract('(?<=Personal,)\\s*([\\d.]+)(?=%)')\n",
    "cybernetics_data['math'] = cybernetics_data['Classification Certainty (Machine Generated)'].str.extract('(?<=Math,)\\s*([\\d.]+)(?=%)')\n",
    "cybernetics_data['psychology'] = cybernetics_data['Classification Certainty (Machine Generated)'].str.extract('(?<=Psychology,)\\s*([\\d.]+)(?=%)')\n",
    "cybernetics_data['machines'] = cybernetics_data['Classification Certainty (Machine Generated)'].str.extract('(?<=Machines,)\\s*([\\d.]+)(?=%)')\n",
    "\n",
    "# Remove all rows with nan\n",
    "cybernetics_data = cybernetics_data.dropna(subset=['Creator']).reset_index(drop=True)\n",
    "\n",
    "# Make a new edges dataframe with the following columns:\n",
    "column_names = ['Source', 'Target', 'Year', 'Personal','Math','Psychology','Machines']\n",
    "all_edges_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# for every document in the main df, make a row in the new dataframe for each pair of creators\n",
    "for row in range(len(cybernetics_data)):\n",
    "    creator_list = cybernetics_data.at[row, 'Creator'].split('||')\n",
    "    if len(creator_list) == 2:\n",
    "        source = creator_list[0]\n",
    "        target = creator_list[1]\n",
    "        year = cybernetics_data.at[row, 'year']\n",
    "        personal = cybernetics_data.at[row, 'personal']\n",
    "        math = cybernetics_data.at[row, 'math']\n",
    "        psychology = cybernetics_data.at[row, 'psychology']\n",
    "        machines = cybernetics_data.at[row, 'machines']\n",
    "        all_edges_df.loc[len(all_edges_df)] = [source, target, year, personal, math, psychology, machines]\n",
    "    elif len(creator_list)>2:\n",
    "        for combination in itertools.combinations(creator_list, 2):\n",
    "            source = combination[0]\n",
    "            target = combination[1]\n",
    "            year = cybernetics_data.at[row, 'year']\n",
    "            personal = cybernetics_data.at[row, 'personal']\n",
    "            math = cybernetics_data.at[row, 'math']\n",
    "            psychology = cybernetics_data.at[row, 'psychology']\n",
    "            machines = cybernetics_data.at[row, 'machines']\n",
    "            all_edges_df.loc[len(all_edges_df)] = [source, target, year, personal, math, psychology, machines]\n",
    "\n",
    "# Add a 'none' column to run the simulation without a topic category\n",
    "all_edges_df['None'] = 100\n",
    "\n",
    "display(all_edges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2245d-f6eb-4551-8869-dcb8a9bc3b0c",
   "metadata": {},
   "source": [
    "<h3>Now we can run our model.</h3>\n",
    "<p>In this simulation, each step represents a year. Every year, a certain number of letters is sent out, which in our model exactly matches the data of actual node connections from that year. In this model, there is some chance that each of those letters might contain the 'new idea' or 'news' that originates with one of our main four 'hub' scientists.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00f1af-222a-4070-a400-ce540853f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set your parameters\n",
    "\n",
    "# The news_index represents the chance that, if one person in a linked pair knows the news, \n",
    "# they will tell the other person in that pair\n",
    "# This should be a number between 0 and 1. The higher the number, the more likely the news will be passed on\n",
    "news_index = .8\n",
    "\n",
    "# seed_nodes is a list with the four hub scientists who are the possible originators of the news or idea\n",
    "# This list could be augmented with any other node names (e.g. \"Einstein, Albert\" or \"Mead, Margaret\")\n",
    "seed_nodes = ['Ashby, W. Ross', 'Wiener, Norbert', 'McCulloch, Warren S.','von Foerster, Heinz']\n",
    "# set as one name if you want to pick a particular seed\n",
    "# set as \"random.choice(seed_nodes)\" if you want it to be a random choice from the list\n",
    "seed = random.choice(seed_nodes)\n",
    "\n",
    "news_topic = ['Personal','Math','Psychology','Machines']\n",
    "# If no topic, set topic = 'None' and all messages/links will have an equal chance of containing the news\n",
    "# set as \"random.choice(news_topic)\" if you want it to be a random choice from the list\n",
    "topic = 'Personal'\n",
    "\n",
    "# the start year represents the \"origin year\" of the news or idea, and the model will begin at that year\n",
    "start_year = 1920\n",
    "end_year = 1975"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f963c0e",
   "metadata": {},
   "source": [
    "<p>Once you've set your parameters you can run the below cell which will print a changing output that shows each step in the simulation, until you hit the final year.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49011cb8-0e4d-4641-b6e5-c4e64a0021c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we draw a network for every year and calculate a chance that that news gets mentioned\n",
    "## At each step we update: the year, letters written, new people informed, % of network that knows the news\n",
    "\n",
    "# set the list of people who know from the beginning (just the seed person)\n",
    "in_the_know = [seed]\n",
    "print (in_the_know)\n",
    "\n",
    "# Make a list of all the nodes in the network so we know what percentage already knows\n",
    "all_nodes = all_edges_df['Source'].tolist() + all_edges_df['Target'].tolist()\n",
    "all_nodes = list(set(all_nodes))\n",
    "\n",
    "# For each year, calculate and print the model output\n",
    "for year in range (start_year, end_year):\n",
    "    clear_output(wait=True)\n",
    "    print (seed)\n",
    "    print (year)\n",
    "    # If any of those letters includes someone in_the_know\n",
    "    letters_links = all_edges_df.loc[all_edges_df['Year'] == year].reset_index(drop=True)\n",
    "    # Make empty list for the people informed in this year\n",
    "    new_folk = []\n",
    "    for row in range(len(letters_links)):\n",
    "        ##check if in the know\n",
    "        source = letters_links.at[row,'Source']\n",
    "        target = letters_links.at[row,'Target']\n",
    "        news_index_num = news_index*(pd.to_numeric(letters_links.at[row,topic])/100)\n",
    "        if source in in_the_know:\n",
    "            delivery_chance = random.uniform(0, 1)\n",
    "            if delivery_chance < news_index_num:\n",
    "            #add the new person to in the know and print them\n",
    "                if target not in in_the_know:\n",
    "                    in_the_know.append (target)\n",
    "                    new_folk.append(target)\n",
    "        elif target in in_the_know:\n",
    "            delivery_chance = random.uniform(0, 1)\n",
    "            if delivery_chance < news_index_num:\n",
    "                if source not in in_the_know:\n",
    "                    #add the new person to in the know and print them    \n",
    "                    in_the_know.append (source)\n",
    "                    new_folk.append(source)\n",
    "\n",
    "    # Print the number of people in the know\n",
    "    print (\"People in the know: \",len(in_the_know))\n",
    "    #print percentage of network in the know\n",
    "    print (\"Percent of network in the know: \", len(in_the_know)/len(all_nodes)*100,'%')\n",
    "    print (\"People who just learned: \")\n",
    "    for i in new_folk:\n",
    "        print (i)\n",
    "    print (\"letters sent this year:\")\n",
    "    print (cybernetics_data.loc[cybernetics_data['year'] == year,['Creator']])\n",
    "\n",
    "    #pause for a second so you can read the output\n",
    "    time.sleep(.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55b615-decf-43de-9a3e-9bd015965c62",
   "metadata": {},
   "source": [
    "<h3>Now we can run a number of trials of this simulation to look at the patterns. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ec505-2b58-4a97-8e54-dbf56865957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set your parameters\n",
    "trials = 20\n",
    "\n",
    "news_index = .8\n",
    "##choose a seed that's one of our four main guys\n",
    "seed_nodes = ['Ashby, W. Ross', 'Wiener, Norbert', 'McCulloch, Warren S.','von Foerster, Heinz']\n",
    "colors = ['r', 'g', 'b', 'c']\n",
    "\n",
    "news_topic = ['Personal','Math','Psychology','Machines', 'None']\n",
    "#if no topic, set topic = 'None' and all messages/links will have an equal chance of containing the news\n",
    "\n",
    "start_year = 1920\n",
    "end_year = 1975\n",
    "\n",
    "## N.B. you need to change the \"seed_choice\" and \"topic_choice\" variables in the for loop \n",
    "# in the next cell in order to change those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6faeb6-1c4f-48ed-aca8-bd4a74a06c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the simulation X times and make a line chart\n",
    "all_nodes = all_edges_df['Source'].tolist() + all_edges_df['Target'].tolist()\n",
    "all_nodes = list(set(all_nodes))\n",
    "\n",
    "# Create a figures\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot each trial\n",
    "for trial in range (trials):\n",
    "    ### Change this to change the initial seed node or make a random choice\n",
    "    seed_choice = random.randint(0, 3)\n",
    "    seed = seed_nodes[seed_choice]\n",
    "    ### Change this to change the topic or make a random choice\n",
    "    # 0-Personal 1-Math 2-Psychology 3-Machines 4-None\n",
    "    topic_choice = 4\n",
    "    topic = news_topic[topic_choice]\n",
    "    in_the_know = [seed]\n",
    "\n",
    "    column_names = ['year', 'no_people', 'percentage']\n",
    "    trial_df = pd.DataFrame(columns=column_names)\n",
    "    trial_df['year'] = range (start_year, end_year)\n",
    "    no_people_peryr = []\n",
    "    percentage_peryr = []\n",
    "    for year in range (start_year, end_year):\n",
    "\n",
    "        letters_links = all_edges_df.loc[all_edges_df['Year'] == year].reset_index(drop=True)\n",
    "        for row in range(len(letters_links)):\n",
    "            source = letters_links.at[row,'Source']\n",
    "            target = letters_links.at[row,'Target']\n",
    "            news_index_num = news_index*(pd.to_numeric(letters_links.at[row,topic])/100)\n",
    "            if (source in in_the_know):\n",
    "                delivery_chance = random.uniform(0, 1)\n",
    "                if delivery_chance < news_index_num:\n",
    "                    in_the_know.append (target)\n",
    "            elif (target in in_the_know):\n",
    "                delivery_chance = random.uniform(0, 1)\n",
    "                if delivery_chance < news_index_num:\n",
    "                    in_the_know.append (source)\n",
    "    \n",
    "        # Number of people in the know\n",
    "        no_people_peryr.append(len(in_the_know))\n",
    "        \n",
    "        # Percentage of network in the know\n",
    "        percentage_peryr.append(len(in_the_know)/len(all_nodes)*100)\n",
    "    \n",
    "    # Save no of people and percentage of network in the know in its own dataframe\n",
    "    trial_df['no_people'] = no_people_peryr\n",
    "    trial_df['percentage'] = percentage_peryr\n",
    "\n",
    "    plt.plot(trial_df['year'], trial_df['no_people'], color=colors[seed_choice], label = seed)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of People\")\n",
    "plt.legend()\n",
    "\n",
    "# Get handles and labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "# Create a dictionary to remove duplicates\n",
    "by_label = dict(zip(labels, handles))\n",
    "\n",
    "# Generate the legend with unique entries\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dab298-f920-42f5-8b4b-a23155a7253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
