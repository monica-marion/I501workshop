{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424b4167-a780-41d3-9a33-5d9c07827031",
   "metadata": {},
   "source": [
    "<h1> 501 Data Pipeline Workshop 9/24 </h1>\n",
    "<h3> Part 1: Data Exploration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f27f1-4ad9-410c-bc1b-aea30c51ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports- these are the python packages used in part 1 of the workshop\n",
    "# Pandas- for manipulating spreadsheet data\n",
    "import pandas as pd\n",
    "# Numpy for calculations\n",
    "import numpy as np\n",
    "# Folium for geographic mapping\n",
    "import folium\n",
    "# Matplotlib for drawing plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53beebf3-e49b-47be-96d3-7654a3873d10",
   "metadata": {},
   "source": [
    "<p>The data we will be using is from U of I's <i>The Cybernetics Thought Collective (Digital Surrogates)</i> </p>\n",
    "<p>It is downloaded as CTC_Machine-Generated-Data.csv from the project's website.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2954cbf-84ba-4ab7-a993-0cc8dedc8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the data from file\n",
    "cybernetics_data = pd.read_csv ('CTC_Machine-Generated-Data.csv')\n",
    "\n",
    "# Display the first three rows of the data as a spreadsheet\n",
    "display(cybernetics_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bde27-6d3e-4b0e-9d49-577624d9c943",
   "metadata": {},
   "source": [
    "<h3>Before we start exploring the data we have on the documents, let's look at where the documents come from by making a geographic map.</h3>\n",
    "<p> The spreadsheet contains a \"Location\" column with the name of a city, we can use these two free map data csvs:\n",
    "<br>\n",
    "https://simplemaps.com/data/world-cities<br>\n",
    "and https://simplemaps.com/data/us-cities<br>\n",
    "to get latitude and longitude data for most of the cities in the dataset.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf07ec-ec7d-4d79-8636-66c71a840032",
   "metadata": {},
   "outputs": [],
   "source": [
    "##make a map\n",
    "#import the city location data csvs\n",
    "world_cities = pd.read_csv (\"worldcities.csv\")\n",
    "us_cities = pd.read_csv (\"uscities.csv\")\n",
    "\n",
    "##make columns in the location dataframes that match the format of the placenames in the cybernetics_data dataframe\n",
    "world_cities['name_id'] = world_cities['city'] + ' (' + world_cities['country']+')'\n",
    "us_cities['name_id'] = us_cities['city'] + ' (' + us_cities['state_id']+')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fc50c-5514-46fe-a26e-25f8a2f33a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##make a new dataframe with: \n",
    "#location names from cybernetics_data, \n",
    "#count of occurences of that place in the data,\n",
    "# and lat and long for that location\n",
    "\n",
    "##make a list of places by separating entries with multiple locations\n",
    "place_list = []\n",
    "for i in cybernetics_data['Location']:\n",
    "    if not pd.isna(i):\n",
    "        place_list.append(i.split('||'))\n",
    "\n",
    "place_list = [item for sublist in place_list for item in sublist]\n",
    "\n",
    "#make a dataframe out of that list of places\n",
    "latlong_df = pd.Series(place_list).value_counts().reset_index()\n",
    "latlong_df.columns = ['name_id', 'count']\n",
    "\n",
    "#bring in the lat and long values from our reference dataframes\n",
    "world_selected = world_cities[['name_id','lat', 'lng']]\n",
    "us_selected = us_cities[['name_id','lat', 'lng']]\n",
    "cities_df = pd.concat([world_selected, us_selected])\n",
    "\n",
    "latlong_df = pd.merge(latlong_df, cities_df, on='name_id', how='left') \n",
    "\n",
    "#manually set the lat and long for Washington, D.C. which is a common location but formatted differently\n",
    "latlong_df.loc[latlong_df['name_id'] == 'Washington (D.C.)', 'lat'] = 38.9047\n",
    "latlong_df.loc[latlong_df['name_id'] == 'Washington (D.C.)', 'lng'] = -77.0163\n",
    "\n",
    "display(latlong_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5b733-c79a-46a1-b76c-71c81835dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot on a map\n",
    "\n",
    "#remove nans\n",
    "map_df = latlong_df.dropna()\n",
    "\n",
    "#instantiate the map object, and set a starting location for the display\n",
    "m = folium.Map(location=[30, -50], zoom_start=2)\n",
    "\n",
    "#add place markers, with transparency so that darker marks represent many overlapping items\n",
    "for lat, lon in zip(map_df['lat'], map_df['lng']):\n",
    "    folium.CircleMarker([lat, lon],\n",
    "                       radius=4,\n",
    "                        color='r',\n",
    "                        fill=True,\n",
    "                        weight=0,\n",
    "                        fill_opacity=0.2\n",
    "                       ).add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36dd75-f163-48a7-be25-4374596ec0a1",
   "metadata": {},
   "source": [
    "<h3>Now let's dig into the columns and variables we have in the data</h3>\n",
    "<h1>From the archive's readme file</h1>\n",
    "<p>\n",
    "* **Master Filename** = Name of the digital object, which is a digitized multi-page bound item or folder of correspondence stored as a PDF. This is human-generated data.\n",
    "\n",
    "* **Level of Description** = Level of archival description of the digital object. All digital objects were described at the file-level. This is human-generated data.\n",
    "          \n",
    "* **Title** = Title of the digital object with which the data are associated. This is a human-readable title that corresponds to the filename for either a folder-level aggregation of correspondence or the title of a bound publication or journal (e.g., \"Mead, Margaret, 1968-71, 1974\" or \"Von Foerster, Heinz, \"On Constructing a Reality,\" BCL Publication 234\"). This is human-generated data.\n",
    "               \n",
    "* **Date** = Date(s) or date range(s) of the archival materials. This is human-generated data.\n",
    "\n",
    "* **Scope and Contents** = Collection-level description of the fonds (or personal papers or record series) digitized for this project. This is human-generated data.\n",
    "\n",
    "* **Creator** = Agent(s) who created the archival materials (this is not always the same as the creator or owner of the personal papers or records). This is human-generated data.\n",
    "\n",
    "* **Associated Person** = Individuals who are subjects within the archival materials. This is machine-generated data.\n",
    "\n",
    "* **Subject** = Subject headings related to the contents of the archival materials. This is human-generated data.\n",
    "\n",
    "* **Location** = Geographical locations associated with the archival materials. This is human-generated data.\n",
    "\n",
    "* **Format of Material** = Type or genre of the materials represented by the digital object, such as correspondence or publication. This is human-generated data.\n",
    "\n",
    "* **Language** = Language(s) of the archival materials. This is human-generated data.\n",
    "\n",
    "* **Cybernetic Classification** = Category into which the digital object has been classified. There are four classifications: Mathematics/Logic; Computers/Machines; Psychology/Neuroscience; and Personal. This is machine-generated data.\n",
    "\n",
    "* **Classification Certainty** = Degree of certainty with which the digital object has been classified (expressed as a percentage). This is machine-generated data.\n",
    "\n",
    "* **Machine-extracted Feature** = Cybernetics entities extracted based on initial inputs found in Cybernetics-Terms_inputs.csv. This is machine-generated data.\n",
    "\n",
    "* **Overall Sentiment** = Compound score for sentiment analysis for the digital object. This is machine-generated data.\n",
    "\n",
    "* **Percent Positive Sentiment** = Score representing proportion of content that is positive. This is machine-generated data.\n",
    "\n",
    "* **Percent Negative Sentiment** = Score representing proportion of content that is negative. This is machine-generated data.\n",
    "\n",
    "* **Percent Neutral Sentiment** = Score representing proportion of content that is neutral. This is machine-generated data.\n",
    "\n",
    "* **Rights** = Copyright terms for the archival materials. This is human-generated data.\n",
    "\n",
    "* **Parent Collection** = Original personal papers or record series to which the archival materials belong. This is human-generated data.\n",
    "\n",
    "* **Repository** = Parent institution which owns the archival materials. This is human-generated data.\n",
    "\n",
    "* **Collection Identifier** = Unique identifier assigned to the personal papers or records series by its parent institution. This is human-generated data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb52c1-014c-4db7-b9f7-71d5aa6f36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also list each column, type of data, and number of unique entries as they are stored in the pandas dataframe\n",
    "\n",
    "#for each column header in the data spreadsheet,\n",
    "for i in cybernetics_data.columns:\n",
    "    #print the column title\n",
    "    print (i)\n",
    "    #print the pandas data type that that column is stored as\n",
    "    print ('Data type: '+ str(cybernetics_data[i].dtype))\n",
    "    #print the number of different values in that column, and a new line for formatting \n",
    "    print ('Number of Unique entries: '+ str(cybernetics_data[i].nunique()), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6024c-2a78-41af-8760-987b5582104e",
   "metadata": {},
   "source": [
    "<h3>Next, let's see how many of the documents in the collection are attributed to each of the main four contributing scientists</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b428d-c48c-400a-b4cc-a03443e1b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "##The document have multiple creators in a list, each name is split by \"||\" so we need to separate them to count\n",
    "\n",
    "#make an empty list to store all the creators\n",
    "creator_list = []\n",
    "\n",
    "#iterate through the dataframe column and split up the names\n",
    "for i in cybernetics_data['Creator']:\n",
    "    if not pd.isna(i):\n",
    "        creator_list.append(i.split('||'))\n",
    "\n",
    "#turn the list of lists into one list\n",
    "creator_list = [item for sublist in creator_list for item in sublist]\n",
    "\n",
    "#make a frequency table of how often each name occurs in the list\n",
    "frequency_table = {}\n",
    "for item in creator_list:\n",
    "    frequency_table[item] = frequency_table.get(item, 0) + 1\n",
    "\n",
    "#sort by number of occurences\n",
    "sorted_items_desc = sorted(frequency_table.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "#print the name and number for the 4 most frequent creators\n",
    "for i in sorted_items_desc[:4]:\n",
    "    print (i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad86b2c2-c391-42ed-81b0-75d2e07dc645",
   "metadata": {},
   "source": [
    "<h3>To start looking at how the system works, we can make a few line plots showing how variables change over time</h3>\n",
    "<p>To do this, we first need to add a new column that standardizes the dates</p>\n",
    "<p>Then we can choose a y variable from any of the numeric columns:\n",
    "               \n",
    "    Overall Sentiment (Machine Generated)\n",
    "               \n",
    "    Percent Positive Sentiment (Machine Generated)\n",
    "               \n",
    "    Percent Negative Sentiment (Machine Generated)\n",
    "               \n",
    "    Percent Neutral Sentiment (Machine Generated)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57453442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x variable will be time\n",
    "# We can choose a y-variable from the numeric columns listed above:\n",
    "y_var = 'Percent Positive Sentiment (Machine Generated)'\n",
    "# Copy and paste a different variable from the list to run the next three cells with that variable\n",
    "# Don't forget the quote marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbe63b-d1c5-474d-ac47-fa3efbd61df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot the relationship between two variables\n",
    "\n",
    "#clean up the dates column, by taking the first year in the entry\n",
    "cybernetics_data['year'] = cybernetics_data['Date'].str.split('-|\\|\\|').str.get(0)\n",
    "cybernetics_data['year'] = cybernetics_data['year'].str.replace(r'[^0-9]', '', regex=True)\n",
    "\n",
    "# Group by year and calculate the mean of your chosen variable for that year\n",
    "average_by_year = cybernetics_data.groupby('year')[y_var].mean().reset_index()\n",
    "\n",
    "x = pd.to_numeric(average_by_year['year'])\n",
    "y = average_by_year[y_var]\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(y_var)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063fbc1a-3cf6-4b3b-af43-98c3b075d1e7",
   "metadata": {},
   "source": [
    "<h3> We can also explore these variables across the different scientists.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46fa91-181d-42d1-90a2-182567a3f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot by creator\n",
    "ashby_df = cybernetics_data[cybernetics_data['Creator'].str.contains('Ashby, W. Ross', na=False)]\n",
    "wiener_df = cybernetics_data[cybernetics_data['Creator'].str.contains('Wiener, Norbert', na=False)]\n",
    "mcculloch_df = cybernetics_data[cybernetics_data['Creator'].str.contains('McCulloch, Warren S.', na=False)]\n",
    "vonfoerster_df = cybernetics_data[cybernetics_data['Creator'].str.contains('von Foerster, Heinz', na=False)]\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ross W. Ashby', 'Norbert Wiener', 'Warren S. McCulloch', 'Heinz von Foerster'],\n",
    "    'Average Sentiment': [ashby_df[y_var].mean(), \n",
    "                          wiener_df[y_var].mean(), \n",
    "                          mcculloch_df[y_var].mean(),  \n",
    "                          vonfoerster_df[y_var].mean()]\n",
    "                          }\n",
    "\n",
    "#make \n",
    "creator_df = pd.DataFrame(data)\n",
    "creator_df.plot.bar(x='Name', y='Average Sentiment')\n",
    "plt.ylabel(y_var)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81b9c2",
   "metadata": {},
   "source": [
    "<h3>When we group the data by creator over time we can start to see the gaps and formatting issues that might complicate results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41cf34-0403-4668-ad69-9e42d2f0a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creator by year\n",
    "\n",
    "ashby_avg = ashby_df.groupby('year')[y_var].mean().reset_index()\n",
    "wiener_avg = wiener_df.groupby('year')[y_var].mean().reset_index()\n",
    "mcculloch_avg = mcculloch_df.groupby('year')[y_var].mean().reset_index()\n",
    "vonfoerster_avg = vonfoerster_df.groupby('year')[y_var].mean().reset_index()\n",
    "\n",
    "##make a new dataframe\n",
    "\n",
    "data = {'year': range(1910,1985)}\n",
    "new_plot_df = pd.DataFrame(data)\n",
    "new_plot_df['year'] = new_plot_df['year'].astype(str)\n",
    "new_plot_df = pd.merge(new_plot_df, ashby_avg, on='year', how='left')\n",
    "new_plot_df = new_plot_df.rename(columns={y_var: 'ashby'})\n",
    "\n",
    "new_plot_df = pd.merge(new_plot_df, wiener_avg, on='year', how='left')\n",
    "new_plot_df = new_plot_df.rename(columns={y_var: 'wiener'})\n",
    "\n",
    "new_plot_df = pd.merge(new_plot_df, mcculloch_avg, on='year', how='left')\n",
    "new_plot_df = new_plot_df.rename(columns={y_var: 'mcculloch'})\n",
    "\n",
    "new_plot_df = pd.merge(new_plot_df, vonfoerster_avg, on='year', how='left')\n",
    "new_plot_df = new_plot_df.rename(columns={y_var: 'vonfoerster'})\n",
    "\n",
    "\n",
    "# Plot col1, col2, and col3 against the index\n",
    "new_plot_df.plot(x = 'year', y=['ashby', 'wiener', 'mcculloch', 'vonfoerster'], kind='line')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(y_var)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba8d324-db53-4650-9777-e160f018f476",
   "metadata": {},
   "source": [
    "<h3>For a last exploration of the data, let's look at the text, via some of the extracted entities provided. How often does a given term pop up in these papers and correspondences over time?</h3>\n",
    "<p>First we'll make a list of the features you can look at, and then plot over time like we've been doing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1eb1d0-31d7-4799-98cb-de08edbc339f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##make a list of all the machine extracted 'features' in the document texts\n",
    "#these are in the column 'Machine-extracted Feature (Machine Generated)'\n",
    "\n",
    "#make an empty list\n",
    "features_list = []\n",
    "\n",
    "#iterate through the dataframe column and split up the entries\n",
    "for i in cybernetics_data['Machine-extracted Feature (Machine Generated)']:\n",
    "    if not pd.isna(i):\n",
    "        features_list.append(i.split('||'))\n",
    "\n",
    "#turn the list of lists into one list\n",
    "features_list = [item for sublist in features_list for item in sublist]\n",
    "\n",
    "#make a frequency table of how often each name occurs in the list\n",
    "frequency_table = {}\n",
    "for item in features_list:\n",
    "    frequency_table[item] = frequency_table.get(item, 0) + 1\n",
    "\n",
    "#sort by number of occurences\n",
    "sorted_items_desc = sorted(frequency_table.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "display(sorted_items_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5719e9e-fa06-400e-9111-4a8d20227564",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can pick one of the above terms and paste it below to look at changes over time\n",
    "term = 'System'\n",
    "\n",
    "#for every year, count number of times that term is in the string\n",
    "years = string_list = [str(x) for x in range(1910,1985)]\n",
    "term_freq = []\n",
    "for year in years:\n",
    "    year_subset = cybernetics_data[cybernetics_data['year'] == year]\n",
    "    if len(year_subset)>0:\n",
    "        count = year_subset['Machine-extracted Feature (Machine Generated)'].str.count(term).sum()\n",
    "        #normalize by number of documents for that year. comment out the line below if you just want total mentions\n",
    "        count = count/len (year_subset)\n",
    "    else:\n",
    "        count = 0\n",
    "    term_freq.append(count)\n",
    "\n",
    "x = pd.to_numeric(years)\n",
    "y = term_freq\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(term)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48248df2-f129-4655-8f23-f32f09880dc0",
   "metadata": {},
   "source": [
    "<h3>Feel free to try this with other variables or explore more parts of the data! In part 2 we will set up a network and predict the flow of information across the \"thought collective\"</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcceb4-859f-4697-a9a1-7d173d886ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code will save the plot from the last cell you ran\n",
    "## You can then download the plot from binder using the navigator on the left\n",
    "plt.savefig(\"class_plot.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
